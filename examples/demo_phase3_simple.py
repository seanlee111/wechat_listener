"""
é˜¶æ®µ3ç®€åŒ–æ¼”ç¤º - å®‰å…¨å»é‡æ¶æ„v2.0
å±•ç¤ºæ ¸å¿ƒåŠŸèƒ½ï¼šå®‰å…¨å»é‡å™¨ã€æ•°æ®éªŒè¯å™¨ã€å·¥ä½œæµç®¡ç†å™¨
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../src'))

import time
from datetime import datetime
from database_v2 import DatabaseV2
from safe_deduplicator import SafeDeduplicator, DedupConfig
from data_validator import DataValidator
from workflow_manager import WorkflowManager, WorkflowConfig

def print_header(title):
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")

def demo_core_features():
    """æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½"""
    print_header("å¾®ä¿¡ç›‘å¬å™¨å®‰å…¨å»é‡æ¶æ„ v2.0 - æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º")
    print(f"æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. æ•°æ®åº“v2.0æ¼”ç¤º
    print_header("1. æ•°æ®åº“æ¶æ„ v2.0")
    db_v2 = DatabaseV2()
    print(f"âœ“ æ•°æ®åº“ç‰ˆæœ¬: {db_v2.get_db_version()}")
    print(f"âœ“ æ•°æ®è¡¨: {db_v2.db.table_names()}")
    
    try:
        raw_count = db_v2.db["messages_raw"].count
        clean_count = db_v2.db["messages_clean"].count
        print(f"âœ“ åŸå§‹æ¶ˆæ¯: {raw_count} æ¡")
        print(f"âœ“ æ¸…æ´æ¶ˆæ¯: {clean_count} æ¡")
        
        unprocessed = db_v2.get_unprocessed_raw_messages(limit=1)
        print(f"âœ“ å¾…å¤„ç†æ¶ˆæ¯: {len(unprocessed)} æ¡ï¼ˆæ ·ä¾‹ï¼‰")
    except Exception as e:
        print(f"âŒ æ•°æ®ç»Ÿè®¡é”™è¯¯: {e}")
    
    # 2. æ•°æ®éªŒè¯å™¨æ¼”ç¤º
    print_header("2. æ•°æ®éªŒè¯å™¨")
    validator = DataValidator(db_v2)
    
    print("æ‰§è¡Œæ•°æ®åº“å®Œæ•´æ€§éªŒè¯...")
    result = validator.validate_database_integrity()
    
    print(f"âœ“ éªŒè¯ç»“æœ: {'é€šè¿‡' if result.is_valid else 'å¤±è´¥'}")
    print(f"âœ“ é”™è¯¯æ•°é‡: {result.error_count}")
    print(f"âœ“ è­¦å‘Šæ•°é‡: {result.warning_count}")
    
    if result.warnings:
        print("ä¸»è¦è­¦å‘Š:")
        for warning in result.warnings[:2]:
            print(f"  - {warning}")
    
    # 3. å®‰å…¨å»é‡å™¨æ¼”ç¤º
    print_header("3. å®‰å…¨å»é‡å™¨")
    
    config = DedupConfig(
        batch_size=100,
        create_backup_before_dedup=False,  # ç®€åŒ–æ¼”ç¤º
        validation_enabled=True
    )
    
    deduplicator = SafeDeduplicator(db_v2, config)
    
    print("æ‰§è¡Œå®‰å…¨å»é‡...")
    start_time = time.time()
    success = deduplicator.execute_safe_deduplication()
    execution_time = time.time() - start_time
    
    if success:
        print("âœ“ å»é‡æ‰§è¡ŒæˆåŠŸ")
        stats = deduplicator.stats
        print(f"âœ“ å¤„ç†æ¶ˆæ¯: {stats.processed_messages} æ¡")
        print(f"âœ“ æ¸…æ´æ¶ˆæ¯: {stats.clean_messages} æ¡")
        print(f"âœ“ é‡å¤æ¶ˆæ¯: {stats.duplicate_messages} æ¡")
        print(f"âœ“ å»é‡æ¯”ä¾‹: {stats.get_dedup_ratio():.2%}")
        print(f"âœ“ æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
    else:
        print("âŒ å»é‡æ‰§è¡Œå¤±è´¥")
    
    # 4. å·¥ä½œæµç®¡ç†å™¨æ¼”ç¤º
    print_header("4. å·¥ä½œæµç®¡ç†å™¨")
    
    workflow_config = WorkflowConfig(
        auto_dedup_enabled=True,
        dedup_threshold=1,
        auto_backup_enabled=False,  # ç®€åŒ–æ¼”ç¤º
        validation_enabled=True
    )
    
    workflow_manager = WorkflowManager(workflow_config)
    workflow_manager.db_v2 = db_v2
    
    print("è·å–ç³»ç»ŸçŠ¶æ€...")
    status = workflow_manager.get_system_status()
    
    db_status = status.get("database", {})
    print(f"âœ“ åŸå§‹æ¶ˆæ¯: {db_status.get('raw_messages', 0)}")
    print(f"âœ“ æ¸…æ´æ¶ˆæ¯: {db_status.get('clean_messages', 0)}")
    print(f"âœ“ å»é‡æ¯”ä¾‹: {db_status.get('dedup_ratio', 0):.2%}")
    
    print("æ‰§è¡Œå®Œæ•´å·¥ä½œæµ...")
    workflow_success = workflow_manager.execute_complete_workflow()
    
    if workflow_success:
        print("âœ“ å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
        final_status = workflow_manager.get_system_status()
        workflow_stats = final_status.get("workflow_stats", {})
        print(f"âœ“ å»é‡æ‰§è¡Œæ¬¡æ•°: {workflow_stats.get('total_dedups_executed', 0)}")
        print(f"âœ“ éªŒè¯æ‰§è¡Œæ¬¡æ•°: {workflow_stats.get('total_validations_performed', 0)}")
    else:
        print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
    
    # 5. æœ€ç»ˆç»Ÿè®¡
    print_header("5. æœ€ç»ˆç»“æœç»Ÿè®¡")
    
    try:
        final_raw = db_v2.db["messages_raw"].count
        final_clean = db_v2.db["messages_clean"].count
        final_logs = db_v2.db["processing_logs"].count
        
        print(f"âœ“ æœ€ç»ˆåŸå§‹æ¶ˆæ¯: {final_raw} æ¡")
        print(f"âœ“ æœ€ç»ˆæ¸…æ´æ¶ˆæ¯: {final_clean} æ¡")
        print(f"âœ“ å¤„ç†æ—¥å¿—è®°å½•: {final_logs} æ¡")
        print(f"âœ“ æ•´ä½“å»é‡æ¯”ä¾‹: {(final_clean/final_raw*100):.1f}%" if final_raw > 0 else "âœ“ æ— æ•°æ®")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        processed_raw = list(db_v2.db.execute(
            "SELECT COUNT(*) FROM messages_raw WHERE processed_status = 1"
        ))[0][0]
        print(f"âœ“ å·²å¤„ç†åŸå§‹æ¶ˆæ¯: {processed_raw} æ¡")
        
    except Exception as e:
        print(f"âŒ æœ€ç»ˆç»Ÿè®¡å‡ºé”™: {e}")
    
    # æ¸…ç†èµ„æº
    workflow_manager.close()
    db_v2.close()
    
    # 6. æ€»ç»“
    print_header("æ¼”ç¤ºå®Œæˆ")
    print("ğŸ‰ é˜¶æ®µ3å®‰å…¨å»é‡æ¶æ„æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
    print("\nâœ¨ ä¸»è¦æˆæœ:")
    print("   âœ“ æ•°æ®åº“æ¶æ„v2.0 - åˆ†å±‚å­˜å‚¨ï¼Œä¿æŠ¤åŸå§‹æ•°æ®")
    print("   âœ“ å®‰å…¨å»é‡å™¨ - é«˜æ•ˆå»é‡ï¼Œä¸åˆ é™¤åŸå§‹æ•°æ®")
    print("   âœ“ æ•°æ®éªŒè¯å™¨ - å®Œæ•´æ€§æ£€æŸ¥å’Œè´¨é‡ç›‘æ§")
    print("   âœ“ å·¥ä½œæµç®¡ç†å™¨ - è‡ªåŠ¨åŒ–å¤„ç†å’ŒçŠ¶æ€ç›‘æ§")
    print("   âœ“ ç³»ç»Ÿé›†æˆ - å„ç»„ä»¶ååŒå·¥ä½œ")
    
    print("\nğŸ”’ å®‰å…¨ç‰¹æ€§:")
    print("   âœ“ åŸå§‹æ•°æ®æ°¸ä¸åˆ é™¤")
    print("   âœ“ åˆ†å±‚å¤„ç†æ¶æ„")
    print("   âœ“ å®Œæ•´çš„æ—¥å¿—è¿½è¸ª")
    print("   âœ“ æ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("   âœ“ é”™è¯¯æ¢å¤æœºåˆ¶")

if __name__ == "__main__":
    try:
        demo_core_features()
    except KeyboardInterrupt:
        print("\n\næ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 